<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    The Chef's Blog
    <title>Bypassing Rate Limits Using The Host Header</title>
    <link rel="stylesheet" href="styles/styles.css">
</head>
<body>
    <header>
        <h1>Bypassing Rate Limits Using The Host Header</h1>
        <div class="social-row">
          <a href="https://github.com/mister-cyber-chef/" class="social-icon">
            <img src="images/IMG_github.jpeg" alt="GitHub Logo">
          </a>

          <a href="https://x.com/mrgosint" title="Mrgosint on X" class="social-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 248 204">
              <path fill="#ffffff" d="M248 24.3a102.2 102.2 0 0 1-29.2 8 51.1 51.1 0 0 0 22.4-28.2 102.6 102.6 0 0 1-32.4 12.4A51.1 51.1 0 0 0 121 63a145 145 0 0 1-105-53 51 51 0 0 0 15.8 68.2A50.9 50.9 0 0 1 10 70.7v.6a51 51 0 0 0 40.9 50 51 51 0 0 1-23 1 51.1 51.1 0 0 0 47.7 35.4A102.7 102.7 0 0 1 0 180.4 145 145 0 0 0 78.5 202c94.3 0 145.9-78.2 145.9-146 0-2.2 0-4.4-.1-6.5A104.4 104.4 0 0 0 248 24.3z"/>
            </svg>
          </a>

          <a href="https://www.linkedin.com/in/mysocialacc" title="LinkedIn" class="social-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512">
              <path fill="#ffffff" d="M100.28 448H7.4V148.9h92.88zm-46.44-341a53.8 53.8 0 1 1 53.8-53.8 53.8 53.8 0 0 1-53.8 53.8zM447.9 448h-92.68V302.4c0-34.7-.7-79.3-48.29-79.3-48.4 0-55.8 37.8-55.8 76.9V448h-92.7V148.9h89v40.8h1.3c12.4-23.5 42.6-48.3 87.7-48.3 93.8 0 111.1 61.7 111.1 141.9z"/>
            </svg>
          </a>
        </div>
        <div id="nav-placeholder"></div>
    </header>
    <article>
        <h2>How Two Domains Opened The Door</h2>
        <p>During a round of testing on an API, I noticed something that did not quite line up with what I expected from the rate limiting in place. Two separate domains, <code>domain1[.]com</code> and <code>domain2[.]com</code>, both pointed to the same backend. Even though they shared the same infrastructure, they seemed to track rate limits separately. By changing the Host header between the two, I was able to send more requests than the system should have allowed.</p>
        <br>
        <p>A quick note before going further. Since testing is ongoing for this client, all names and values here are replaced with stand in data.</p>
        <br>
        <h3>What I Observed While Testing</h3>
        <p>When I sent repeated requests to <code>domain1[.]com/&lt;user&gt;/</code>, the system eventually started blocking me after roughly one thousand requests. That part made sense. What surprised me was that, if I then sent the same type of requests but changed the Host header to <code>domain2[.]com</code>, the server allowed another large batch of requests without complaint, even though both domains relied on the same backend.</p>
        
        <p>To confirm they truly shared the same backend, I ran a few simple DNS lookups and checked the records:</p>
        <pre>
$ dig domain1.com +noall +answer
domain1.com.     0       IN      CNAME   cname1.com.
cname1.com.      0       IN      A       x.x.x.19

$ dig domain2.com +noall +answer
domain2.com.     0       IN      CNAME   cname1.com.
cname1.com.      0       IN      A       x.x.x.19

$ dig -x x.x.x.19 +noall +answer
x.x.x.31.in-addr.arpa. 0     IN      PTR     PTR1.com.
        </pre>
        <p>Both <code>domain1[.]com</code> and <code>domain2[.]com</code> resolved to the same IP address <code>x.x.x.19</code>. So while they looked like different entry points from the outside, behind the scenes they led to the same place.</p>

        <h3>Numbers That Tell The Story</h3>
        <p>To understand how much extra traffic this allowed, I recorded how many requests each domain would accept before the rate limit kicked in. The table below summarizes what I saw during testing:</p>
        <table>
            <thead>
                <tr>
                    <th>Endpoint</th>
                    <th>Host Header</th>
                    <th># of Requests</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td>Node (API)</td>
                    <td>domain1.com</td>
                    <td>1,138</td>
                </tr>
                <tr>
                    <td>Node (API)</td>
                    <td>domain2.com</td>
                    <td>1,098</td>
                </tr>
                <tr>
                    <td>Query (GraphQL)</td>
                    <td>domain1.com</td>
                    <td>3,570</td>
                </tr>
                <tr>
                    <td>Query (GraphQL)</td>
                    <td>domain2.com</td>
                    <td>3,808</td>
                </tr>
            </tbody>
        </table>
        <p>By swapping the Host header between <code>domain1[.]com</code> and <code>domain2[.]com</code>, I could almost double the amount of traffic I was able to send before running into any limits. For someone who wants to push a system hard, this is more than enough to matter.</p>

        <h3>Why This Behavior Is Concerning</h3>
        <p>On the surface, this might look like a small difference in configuration, but the impact can be meaningful. Here are a few reasons why this stands out to me:</p>
        <ul>
            <li><strong>More Effective Scraping:</strong> If someone wants to scrape data, they can stretch out the limit simply by rotating through domains that share the same backend.</li>
            <li><strong>Extra Load On Servers:</strong> Allowing more requests than expected can place additional stress on backend systems and introduce performance issues for real users.</li>
            <li><strong>Gaps In Detection:</strong> If monitoring and alerting rely heavily on rate limit triggers, this type of behavior might allow aggressive traffic to avoid drawing attention.</li>
        </ul>

        <h3>Some Possible Explanations</h3>
        <p>I did not have access to the internal configuration, so I can only share possible reasons based on what I have seen in similar setups:</p>
        <ol>
            <li><strong>Limits Tracked Per Domain:</strong> The rate limiting logic may be using the value of the Host header as part of the key to track usage. If that is the case, each domain ends up with its own counter even though they share the same backend.</li>
            <li><strong>Behavior At The Load Balancer Or Proxy:</strong> A load balancer or reverse proxy might be applying rate limits before traffic reaches the application. If limits are enforced per incoming domain rather than per shared backend, this behavior would make sense from the system’s point of view.</li>
            <li><strong>Separate Contexts That Do Not Talk To Each Other:</strong> It is also possible that the system maintains separate rate limit contexts for each domain for operational reasons, but did not fully account for the fact that some clients may be able to move between those domains easily.</li>
        </ol>

        <h3>What This Tells Us About Design</h3>
        <p>To me, this experience reinforces how important it is to think about limits from the perspective of the entire system, not just one entry point at a time. If multiple domains share the same backend, then rate limits ideally should reflect that shared reality. Otherwise, the system can end up with blind spots that are not obvious until someone actively tests for them.</p>

        <h3>Closing Thoughts</h3>
        <p>I do not see this as a simple configuration mistake. Instead, it feels more like one of those subtle architectural gaps that only show up under specific conditions. It is the kind of thing that is easy to miss when adding new domains or adjusting traffic flows over time.</p>
        <p>Finding and sharing issues like this is meant to help everyone involved. It gives the team a chance to adjust their protections so that limits are applied more consistently across the whole environment. In the long run that leads to a more reliable and resilient system for both users and operators.</p>
    <br>
        <h3>If you are curious about how I worked through this, I put together a small mind map that captures my thought process. It was a good reminder that sometimes small details in headers can tell you a lot.</h3>
    <br>
<div style="width: 1700opx; height: 400px; overflow: auto; border: 2px solid #666;">
    <img src="images/header_swap_mind_map.png" style="width: 1700px; height: 400px;" alt="Mind Map Image">
</div>
    </article>
    <footer>
        <div class="centered">
            <em><p id="footer-year">The Chef's Blog | Copyright © <span></span> | All rights reserved.</p></em>
        </div>
    </footer>

    <!-- get footer Year -->
    <script>
        document.querySelector("#footer-year span").textContent = new Date().getFullYear();
    </script>
</body>
<script>
function initNavToggle() {
  const nav = document.querySelector(".site-nav");
  if (!nav) return;

  const toggle = nav.querySelector(".nav-toggle");
  const links = nav.querySelector(".nav-links");

  toggle.addEventListener("click", () => {
    const isOpen = nav.classList.toggle("open");
    toggle.setAttribute("aria-expanded", isOpen ? "true" : "false");
  });

  // close menu when a link is clicked
  links.addEventListener("click", (e) => {
    if (e.target.tagName.toLowerCase() === "a") {
      nav.classList.remove("open");
      toggle.setAttribute("aria-expanded", "false");
    }
  });
}

fetch("nav.html")
  .then(res => res.text())
  .then(html => {
    const placeholder = document.getElementById("nav-placeholder");
    placeholder.innerHTML = html;
    initNavToggle();
  });
</script>
</html>
